{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cd2eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GRADIENT BOOSTING CLASSIFICATION\n",
      "============================================================\n",
      "\n",
      "Training samples: 800\n",
      "Test samples: 200\n",
      "Features: 20\n",
      "\n",
      "Training Gradient Boosting Classifier...\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.2987           0.0740            3.37s\n",
      "         2           1.2306           0.0726            2.38s\n",
      "         3           1.1721           0.0484            2.04s\n",
      "         4           1.1186           0.0642            1.92s\n",
      "         5           1.0795           0.0820            1.94s\n",
      "         6           1.0254           0.0082            2.06s\n",
      "         7           0.9938           0.0770            2.04s\n",
      "         8           0.9484          -0.0091            1.92s\n",
      "         9           0.9173           0.0226            1.81s\n",
      "        10           0.8977           0.0543            2.57s\n",
      "        20           0.6769          -0.0245            1.64s\n",
      "        30           0.5510           0.0199            1.24s\n",
      "        40           0.4465           0.0024            1.01s\n",
      "        50           0.3756          -0.0470            0.84s\n",
      "        60           0.3278           0.0069            0.67s\n",
      "        70           0.2997           0.0179            0.53s\n",
      "        80           0.2494          -0.0235            0.41s\n",
      "        90           0.2240          -0.0153            0.22s\n",
      "       100           0.2099           0.0088            0.00s\n",
      "\n",
      "Accuracy: 0.9000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       106\n",
      "           1       0.88      0.91      0.90        94\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.90      0.90       200\n",
      "weighted avg       0.90      0.90      0.90       200\n",
      "\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3050           0.0551            1.26s\n",
      "         2           1.2410           0.0758            1.18s\n",
      "         3           1.1702           0.0463            1.22s\n",
      "         4           1.1189           0.0378            1.32s\n",
      "         5           1.0789           0.0661            1.31s\n",
      "         6           1.0365           0.0618            1.36s\n",
      "         7           0.9989           0.0518            1.29s\n",
      "         8           0.9667           0.0457            1.26s\n",
      "         9           0.9205           0.0078            1.23s\n",
      "        10           0.8806           0.0033            1.19s\n",
      "        20           0.6503           0.0029            1.04s\n",
      "        30           0.5164           0.0632            0.95s\n",
      "        40           0.4296           0.0847            0.79s\n",
      "        50           0.3428          -0.0436            0.64s\n",
      "        60           0.3085           0.0309            0.52s\n",
      "        70           0.2508          -0.0336            0.39s\n",
      "        80           0.2262           0.0196            0.26s\n",
      "        90           0.1960           0.0032            0.13s\n",
      "       100           0.1807           0.0359            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3066           0.0667            1.00s\n",
      "         2           1.2369           0.0595            1.12s\n",
      "         3           1.1766           0.0557            1.15s\n",
      "         4           1.1229           0.0682            1.12s\n",
      "         5           1.0706           0.0374            1.09s\n",
      "         6           1.0382           0.0888            1.07s\n",
      "         7           0.9941           0.0349            1.06s\n",
      "         8           0.9567           0.0368            1.04s\n",
      "         9           0.9230           0.0224            1.03s\n",
      "        10           0.8821           0.0059            1.02s\n",
      "        20           0.6909           0.0422            1.12s\n",
      "        30           0.5456          -0.0005            1.14s\n",
      "        40           0.4604           0.1061            1.11s\n",
      "        50           0.3790          -0.0684            0.89s\n",
      "        60           0.3355          -0.0024            0.69s\n",
      "        70           0.2862          -0.0340            0.50s\n",
      "        80           0.2547           0.0054            0.33s\n",
      "        90           0.2232          -0.0115            0.16s\n",
      "       100           0.2074           0.0455            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3089           0.0737            1.25s\n",
      "         2           1.2370           0.0333            1.12s\n",
      "         3           1.1835           0.0894            1.10s\n",
      "         4           1.1286           0.0539            1.10s\n",
      "         5           1.0895           0.0708            1.07s\n",
      "         6           1.0553           0.0512            1.07s\n",
      "         7           1.0070           0.0097            1.08s\n",
      "         8           0.9771           0.0555            1.06s\n",
      "         9           0.9350          -0.0057            1.05s\n",
      "        10           0.9033           0.0523            1.04s\n",
      "        20           0.6690           0.0638            0.94s\n",
      "        30           0.5380          -0.0263            0.82s\n",
      "        40           0.4631           0.0766            0.70s\n",
      "        50           0.3798          -0.0806            0.59s\n",
      "        60           0.3448           0.0027            0.48s\n",
      "        70           0.3015          -0.0128            0.36s\n",
      "        80           0.2738          -0.0045            0.24s\n",
      "        90           0.2363          -0.0193            0.12s\n",
      "       100           0.2197           0.0151            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3040           0.0616            1.22s\n",
      "         2           1.2302           0.0739            1.32s\n",
      "         3           1.1767           0.0850            1.22s\n",
      "         4           1.1108           0.0234            1.20s\n",
      "         5           1.0735           0.0644            1.22s\n",
      "         6           1.0358           0.0542            1.25s\n",
      "         7           0.9901           0.0168            1.27s\n",
      "         8           0.9511           0.0133            1.28s\n",
      "         9           0.9243           0.0574            1.28s\n",
      "        10           0.8932           0.0406            1.29s\n",
      "        20           0.6800           0.0684            1.18s\n",
      "        30           0.5337          -0.0175            1.10s\n",
      "        40           0.4331           0.0116            1.10s\n",
      "        50           0.3702          -0.0341            0.87s\n",
      "        60           0.3109          -0.0386            0.68s\n",
      "        70           0.2890           0.0040            0.50s\n",
      "        80           0.2505           0.0046            0.33s\n",
      "        90           0.2243           0.0116            0.16s\n",
      "       100           0.2022           0.0201            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3065           0.0652            1.07s\n",
      "         2           1.2338           0.0683            1.12s\n",
      "         3           1.1767           0.0650            1.15s\n",
      "         4           1.1162           0.0301            1.14s\n",
      "         5           1.0874           0.1054            1.09s\n",
      "         6           1.0371           0.0170            1.09s\n",
      "         7           0.9952           0.0124            1.08s\n",
      "         8           0.9578           0.0310            1.07s\n",
      "         9           0.9284           0.0600            1.07s\n",
      "        10           0.8982           0.0428            1.07s\n",
      "        20           0.6793           0.0384            0.95s\n",
      "        30           0.5401          -0.0437            0.83s\n",
      "        40           0.4461          -0.0248            0.71s\n",
      "        50           0.3964           0.0207            0.59s\n",
      "        60           0.3377           0.0100            0.47s\n",
      "        70           0.3053           0.0281            0.35s\n",
      "        80           0.2581           0.0035            0.24s\n",
      "        90           0.2331           0.0434            0.12s\n",
      "       100           0.2053           0.0066            0.00s\n",
      "Cross-validation scores: [0.855 0.895 0.945 0.89  0.92 ]\n",
      "Mean CV score: 0.9010 (+/- 0.0605)\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "   Feature  Importance\n",
      "Feature_12    0.182293\n",
      " Feature_2    0.101653\n",
      " Feature_5    0.100546\n",
      "Feature_16    0.070862\n",
      " Feature_4    0.070818\n",
      " Feature_0    0.063366\n",
      " Feature_6    0.055526\n",
      "Feature_10    0.052894\n",
      " Feature_9    0.051549\n",
      "Feature_17    0.048365\n",
      "\n",
      "Training deviance: 0.2099\n",
      "Number of iterations: 100\n",
      "\n",
      "============================================================\n",
      "GRADIENT BOOSTING REGRESSION\n",
      "============================================================\n",
      "\n",
      "Training Gradient Boosting Regressor...\n",
      "\n",
      "Mean Squared Error: 7035.4930\n",
      "Root Mean Squared Error: 83.8778\n",
      "R² Score: 0.8623\n",
      "\n",
      "Top 10 Feature Importances (Regression):\n",
      "   Feature  Importance\n",
      " Feature_3    0.195742\n",
      " Feature_2    0.142414\n",
      "Feature_13    0.114556\n",
      " Feature_8    0.113249\n",
      "Feature_14    0.097001\n",
      " Feature_0    0.092179\n",
      " Feature_9    0.081483\n",
      "Feature_12    0.059239\n",
      " Feature_6    0.035680\n",
      "Feature_16    0.025609\n",
      "\n",
      "============================================================\n",
      "STAGED PREDICTIONS (Prediction at each boosting stage)\n",
      "============================================================\n",
      "\n",
      "Accuracy at stage 10: 0.8150\n",
      "Accuracy at stage 50: 0.8750\n",
      "Accuracy at stage 100: 0.9000\n",
      "\n",
      "Gradient Boosting model training complete!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GRADIENT BOOSTING CLASSIFICATION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Generate classification dataset\n",
    "X_clf, y_clf = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train_clf.shape[0]}\")\n",
    "print(f\"Test samples: {X_test_clf.shape[0]}\")\n",
    "print(f\"Features: {X_train_clf.shape[1]}\\n\")\n",
    "\n",
    "# Create and train Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training Gradient Boosting Classifier...\")\n",
    "gb_clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_clf = gb_clf.predict(X_test_clf)\n",
    "y_pred_proba = gb_clf.predict_proba(X_test_clf)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test_clf, y_pred_clf)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_clf, y_pred_clf))\n",
    "\n",
    "# Cross-validation score\n",
    "cv_scores = cross_val_score(gb_clf, X_clf, y_clf, cv=5)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = gb_clf.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': [f'Feature_{i}' for i in range(len(feature_importance))],\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# Training deviance (loss over iterations)\n",
    "print(f\"\\nTraining deviance: {gb_clf.train_score_[-1]:.4f}\")\n",
    "print(f\"Number of iterations: {len(gb_clf.train_score_)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRADIENT BOOSTING REGRESSION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Generate regression dataset\n",
    "X_reg, y_reg = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    noise=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create and train Gradient Boosting Regressor\n",
    "gb_reg = GradientBoostingRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    subsample=0.8,\n",
    "    loss='squared_error',\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Training Gradient Boosting Regressor...\")\n",
    "gb_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_reg = gb_reg.predict(X_test_reg)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(f\"\\nMean Squared Error: {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Feature importance for regression\n",
    "feature_importance_reg = gb_reg.feature_importances_\n",
    "importance_df_reg = pd.DataFrame({\n",
    "    'Feature': [f'Feature_{i}' for i in range(len(feature_importance_reg))],\n",
    "    'Importance': feature_importance_reg\n",
    "}).sort_values('Importance', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Feature Importances (Regression):\")\n",
    "print(importance_df_reg.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STAGED PREDICTIONS (Prediction at each boosting stage)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Staged predictions - useful for finding optimal n_estimators\n",
    "staged_preds = list(gb_clf.staged_predict(X_test_clf))\n",
    "staged_accuracy = [accuracy_score(y_test_clf, pred) for pred in staged_preds]\n",
    "\n",
    "print(f\"Accuracy at stage 10: {staged_accuracy[9]:.4f}\")\n",
    "print(f\"Accuracy at stage 50: {staged_accuracy[49]:.4f}\")\n",
    "print(f\"Accuracy at stage 100: {staged_accuracy[99]:.4f}\")\n",
    "\n",
    "print(\"\\nGradient Boosting model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d1400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
